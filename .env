# .env file - Environment Variables Configuration

# Server Configuration
NODE_ENV=development
PORT=3000
HOST=localhost

# Database Configuration
MONGODB_URI=mongodb+srv://shubhamvumap:19MadShubh96@cluster0.scdun4g.mongodb.net/video-transcription
MONGODB_USER=
MONGODB_PASSWORD=

# File Upload Configuration
MAX_FILE_SIZE=500000000  # 500MB in bytes
UPLOAD_PATH=./uploads
ALLOWED_FILE_TYPES=video/mp4,video/avi,video/mov,video/wmv,audio/mp3,audio/wav,audio/m4a

# Whisper Configuration
WHISPER_PATH=whisper
WHISPER_MODEL=base
WHISPER_LANGUAGE=en
WHISPER_TIMEOUT=1800000  # 30 minutes in milliseconds

# LLM Configuration
LLM_PROVIDER=ollama  # ollama, gpt4all, llamacpp
LLM_ENDPOINT=http://localhost:11434/api/generate
LLM_MODEL=llama2
LLM_TIMEOUT=60000  # 60 seconds
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.7

# Alternative LLM Configurations
# For GPT4All
GPT4ALL_PATH=gpt4all
GPT4ALL_MODEL=gpt4all-falcon-q4_0.bin

# For llama.cpp
LLAMACPP_ENDPOINT=http://localhost:8080/completion
LLAMACPP_MODEL_PATH=/path/to/model.bin

# Question Generation Configuration
QUESTIONS_PER_SEGMENT=3
SEGMENT_DURATION=300  # 5 minutes in seconds
MIN_SEGMENT_WORDS=50

# Logging Configuration
LOG_LEVEL=info
LOG_FILE=./logs/app.log
ENABLE_REQUEST_LOGGING=true

# Security Configuration
CORS_ORIGIN=http://localhost:3000,http://localhost:3001
RATE_LIMIT=100  # requests per 15 minutes
ENABLE_HELMET=true

# Performance Configuration
CLUSTER_MODE=false
MAX_CONCURRENT_TRANSCRIPTIONS=3
CLEANUP_INTERVAL=3600000  # 1 hour in milliseconds
TEMP_FILE_RETENTION=86400000  # 24 hours in milliseconds

# Monitoring Configuration
ENABLE_HEALTH_CHECK=true
HEALTH_CHECK_INTERVAL=30000  # 30 seconds
ENABLE_METRICS=false
METRICS_PORT=9090